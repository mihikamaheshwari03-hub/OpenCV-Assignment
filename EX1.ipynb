{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe65998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "OpenCV version: 4.12.0\n"
     ]
    }
   ],
   "source": [
    "# Core libraries for computer vision\n",
    "import cv2  # OpenCV - the main computer vision library\n",
    "import numpy as np  # Numerical operations on arrays/images\n",
    "\n",
    "# Libraries for display in Jupyter Notebook\n",
    "from PIL import Image, ImageDraw, ImageFont  # Python Imaging Library\n",
    "from IPython.display import display, clear_output\n",
    "import IPython.display\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e66874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(frame_size=(400, 250), columns=2, **kwargs):\n",
    "    \"\"\"\n",
    "    Display multiple images in a grid with labels.\n",
    "    \n",
    "    Args:\n",
    "        frame_size: Size for each image\n",
    "        columns: Number of columns in the grid\n",
    "        **kwargs: Dictionary of images with labels as keys\n",
    "    \n",
    "    Example:\n",
    "        plot_images(**{\"Original\": img1, \"Blurred\": img2, \"Edges\": img3})\n",
    "    \"\"\"\n",
    "    if not kwargs:\n",
    "        print(\"No images provided!\")\n",
    "        return None\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label, frame in kwargs.items():\n",
    "        # Ensure images are uint8\n",
    "        if frame.dtype != np.uint8:\n",
    "            frame = (frame * 255).astype(np.uint8)\n",
    "        \n",
    "        # Handle grayscale images\n",
    "        if len(frame.shape) == 2:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, frame_size)\n",
    "        \n",
    "        images.append(Image.fromarray(frame))\n",
    "        labels.append(label)\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    cols = max(1, columns)\n",
    "    rows = int(np.ceil(len(images) / cols))\n",
    "    \n",
    "    # Create canvas\n",
    "    label_height = 40\n",
    "    combined_width = frame_size[0] * cols\n",
    "    combined_height = rows * (frame_size[1] + label_height)\n",
    "    combined_img = Image.new(\"RGB\", (combined_width, combined_height), (255, 255, 255))\n",
    "    \n",
    "    # Draw images and labels\n",
    "    draw = ImageDraw.Draw(combined_img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 18)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    for idx, (img_pil, label) in enumerate(zip(images, labels)):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        x_offset = col * frame_size[0]\n",
    "        y_offset = row * (frame_size[1] + label_height)\n",
    "        \n",
    "        # Draw label\n",
    "        draw.text((x_offset + 10, y_offset + 10), label, fill=\"black\", font=font)\n",
    "        \n",
    "        # Paste image\n",
    "        combined_img.paste(img_pil, (x_offset, y_offset + label_height))\n",
    "\n",
    "    display(combined_img)\n",
    "    \n",
    "    return combined_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17774158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_correction(image, gamma=1.2):\n",
    "    \"\"\"Apply gamma correction\"\"\"\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([\n",
    "        ((i / 255.0) ** inv_gamma) * 255\n",
    "        for i in np.arange(0, 256)\n",
    "    ]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "\n",
    "def intensity_normalization(image):\n",
    "    \"\"\"Normalize intensity to full [0,255] range\"\"\"\n",
    "    normalized = cv2.normalize(\n",
    "        image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX\n",
    "    )\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07545ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_threshold(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    return(cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "def otsu_threshold(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, otsu = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY+ cv2.THRESH_OTSU)\n",
    "    return(cv2.cvtColor(otsu, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "def adaptive_threshold(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                     cv2.THRESH_BINARY, 11, 2)\n",
    "    return(cv2.cvtColor(adaptive, cv2.COLOR_GRAY2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eda6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erosion(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    \n",
    "    # Erosion - removes small white regions\n",
    "    eroded = cv2.erode(gray, kernel, iterations=1)\n",
    "    return(cv2.cvtColor(eroded, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "def dilation(image):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    \n",
    "    # Erosion - removes small white regions\n",
    "    dilated = cv2.dilate(image, kernel, iterations=1)\n",
    "    return(cv2.cvtColor(dilated, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "def closing(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    \n",
    "    # Erosion - removes small white regions\n",
    "    closed = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "    return(cv2.cvtColor(closed, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "def opening(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    \n",
    "    # Erosion - removes small white regions\n",
    "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "    return(cv2.cvtColor(opened, cv2.COLOR_GRAY2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608bbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened successfully.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('Mallet_videos/IMG_9105.MOV')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file. Check the path and file format.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"Video opened successfully.\")\n",
    "\n",
    "desired_width = 640\n",
    "desired_height = 1000\n",
    "display_size = (desired_width, desired_height)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# CLAHE object for contrast enhancementfinal_mask\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Resize (BGR, 3-channel)\n",
    "    # --------------------------------------\n",
    "    resized_frame = cv2.resize(\n",
    "        frame, display_size, interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Convert to LAB (ONLY cvtColor used)\n",
    "    # --------------------------------------\n",
    "    lab_img = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2LAB)\n",
    "    L, A, B = cv2.split(lab_img)\n",
    "    lab_img2= cv2.cvtColor(resized_frame, cv2.COLOR_BGR2HSV)\n",
    "    H, S, V = cv2.split(lab_img2)\n",
    "    B2, G, R = cv2.split(resized_frame)\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Single-channel processing starts here\n",
    "    # --------------------------------------\n",
    "    img1 = cv2.GaussianBlur(, (7, 7), 0)\n",
    "\n",
    "\n",
    "    img2 = gamma_correction(img1, gamma=1.5)\n",
    "    img = intensity_normalization(img2)\n",
    "    \n",
    "    alpha = 0.9 # Contrast control (1.0-3.0 range is common for manual adjust)\n",
    "    beta = 0    # Brightness control\n",
    "\n",
    "    img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    # --------------------------------------\n",
    "    # THRESHOLDING (INLINE, SAFE)\n",
    "    # --------------------------------------\n",
    "\n",
    "    # Binary threshold\n",
    "    _, binary = cv2.threshold(\n",
    "        img, 140, 255, cv2.THRESH_BINARY\n",
    "    )\n",
    "\n",
    "    # Otsu threshold\n",
    "    _, otsu = cv2.threshold(\n",
    "        img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    # Adaptive threshold\n",
    "    adaptive = cv2.adaptiveThreshold(\n",
    "        img,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        41,\n",
    "        7\n",
    "    )\n",
    "\n",
    "    # Combine Binary & Otsu\n",
    "    combined = cv2.bitwise_and(binary, otsu)\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Morphology (1-channel only)\n",
    "    # --------------------------------------\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "\n",
    "    \n",
    "    \n",
    "    opened = cv2.morphologyEx(combined, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    # closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    \n",
    "  \n",
    "\n",
    "    # Enforce clean binary\n",
    "    _,closed = cv2.threshold(closed, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    closed = closed.astype(np.uint8)\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Connected Components (FINAL MASK)\n",
    "    # --------------------------------------\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n",
    "        closed, connectivity=8\n",
    "    )\n",
    "\n",
    "    final_mask = np.zeros_like(closed)\n",
    "    for i in range(1, num_labels):\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        if area >= 100 and area <= 5000:  # Minimum area threshold\n",
    "            final_mask[labels == i] = 255   \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Apply mask to original frame\n",
    "    # --------------------------------------\n",
    "    masked_output = cv2.bitwise_and(\n",
    "        resized_frame, resized_frame, mask=final_mask\n",
    "    )\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Visualization\n",
    "    # --------------------------------------\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    cv2.imshow(\"Original\", resized_frame)\n",
    "    cv2.imshow(\"Binary\", binary)\n",
    "    cv2.imshow(\"Otsu\", otsu)\n",
    "    cv2.imshow(\"Adaptive\", adaptive)\n",
    "    # cv2.imshow(\"combined\", combined)\n",
    "    # cv2.imshow(\"Refined\", closed)\n",
    "    cv2.imshow(\"Final Mask\", final_mask)\n",
    "    cv2.imshow(\"Masked Output\", masked_output)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(int(1000 / fps)) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "254e7223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# cap = cv2.VideoCapture(\"Mallet_videos/IMG_9105.MOV\")\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     frame = cv2.resize(frame, (640, 1000))\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Downscale\n",
    "#     # -----------------------------\n",
    "#     small = cv2.resize(frame, None, fx=0.5, fy=0.5)\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Convert to HSV\n",
    "#     # -----------------------------\n",
    "#     hsv = cv2.cvtColor(small, cv2.COLOR_BGR2HSV)\n",
    "#     H, S, V = cv2.split(hsv)\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Prepare K-Means data (H + S ONLY)\n",
    "#     # -----------------------------\n",
    "#     Z = np.stack((H.flatten(), S.flatten()), axis=1)\n",
    "#     Z = np.float32(Z)\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # K-Means\n",
    "#     # -----------------------------\n",
    "#     criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "#     K = 4   # fewer clusters work better in HS space\n",
    "\n",
    "#     _, labels, centers = cv2.kmeans(\n",
    "#         Z,\n",
    "#         K,\n",
    "#         None,\n",
    "#         criteria,\n",
    "#         10,\n",
    "#         cv2.KMEANS_RANDOM_CENTERS\n",
    "#     )\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Select mallet cluster\n",
    "#     # (highest saturation)\n",
    "#     # -----------------------------\n",
    "#     cluster_sat = []\n",
    "#     for i in range(K):\n",
    "#         sat = np.mean(Z[labels.flatten() == i][:, 1])\n",
    "#         cluster_sat.append(sat)\n",
    "\n",
    "#     mallet_cluster = np.argmax(cluster_sat)\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Binary mask\n",
    "#     # -----------------------------\n",
    "#     labels_2d = labels.reshape(small.shape[:2])\n",
    "#     mask_small = np.zeros_like(labels_2d, dtype=np.uint8)\n",
    "#     mask_small[labels_2d == mallet_cluster] = 255\n",
    "\n",
    "#     mask = cv2.resize(\n",
    "#         mask_small,\n",
    "#         (frame.shape[1], frame.shape[0]),\n",
    "#         interpolation=cv2.INTER_NEAREST\n",
    "#     )\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Morphological cleanup\n",
    "#     # -----------------------------\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "#     mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "#     mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Apply mask\n",
    "#     # -----------------------------\n",
    "#     result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Display\n",
    "#     # -----------------------------\n",
    "#     cv2.imshow(\"Original\", frame)\n",
    "#     cv2.imshow(\"Mallet Mask\", mask)\n",
    "#     cv2.imshow(\"Segmented Mallet\", result)\n",
    "\n",
    "\n",
    "\n",
    "#     if cv2.waitKey(int(1000 / fps)) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13ad7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture('Mallet_videos/IMG_9113.MOV')\n",
    "\n",
    "# if not cap.isOpened():\n",
    "#     print(\"Error opening video file. Check the path and file format.\")\n",
    "#     exit()\n",
    "# else:\n",
    "#     print(\"Video opened successfully.\")\n",
    "\n",
    "# desired_width = 640\n",
    "# desired_height = 1000\n",
    "# display_size = (desired_width, desired_height)\n",
    "\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# # CLAHE object for contrast enhancementfinal_mask\n",
    "# clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # --------------------------------------\n",
    "#     # Resize (BGR, 3-channel)\n",
    "#     # --------------------------------------\n",
    "#     resized_frame = cv2.resize(\n",
    "#         frame, display_size, interpolation=cv2.INTER_AREA\n",
    "#     )\n",
    "#     h, w = resized_frame.shape[:2]\n",
    "#     small = cv2.resize(frame, None, fx=0.5, fy=0.5)\n",
    "#     Z = small.reshape((-1,3))\n",
    "#     # convert to np.float32\n",
    "#     Z = np.float32(Z)\n",
    "#     # define criteria, number of clusters(K) and apply kmeans()\n",
    "#     criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "#     K = 8\n",
    "#     ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "#     # Now convert back into uint8, and make original image\n",
    "#     center = np.uint8(center)\n",
    "#     res = center[label.flatten()]\n",
    "#     res2 = res.reshape((small.shape))\n",
    "#     cv2.imshow('Kmeans',res2)\n",
    "#     # --------------------------------------\n",
    "#     # Convert to LAB (ONLY cvtColor used)\n",
    "#     # --------------------------------------\n",
    "#     lab_img = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2LAB)\n",
    "#     L, A, B = cv2.split(lab_img)\n",
    "#     lab_img2= cv2.cvtColor(resized_frame, cv2.COLOR_BGR2HSV)\n",
    "#     H, S, V = cv2.split(lab_img2)\n",
    "#     B2, G, R = cv2.split(resized_frame)\n",
    "\n",
    "#     # --------------------------------------\n",
    "#     # Single-channel processing starts here\n",
    "#     # --------------------------------------\n",
    "#     img1 = cv2.GaussianBlur(B, (7, 7), 0)\n",
    "\n",
    "\n",
    "#     img2 = gamma_correction(img1, gamma=1.5)\n",
    "#     img = intensity_normalization(img2)\n",
    "    \n",
    "#     alpha = 0.9 # Contrast control (1.0-3.0 range is common for manual adjust)\n",
    "#     beta = 0    # Brightness control\n",
    "\n",
    "#     img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "#     img = img.astype(np.uint8)\n",
    "\n",
    "#     # --------------------------------------\n",
    "#     # THRESHOLDING (INLINE, SAFE)\n",
    "#     # --------------------------------------\n",
    "\n",
    "#     # Binary threshold\n",
    "#     _, binary = cv2.threshold(\n",
    "#         img, 140, 255, cv2.THRESH_BINARY\n",
    "#     )\n",
    "\n",
    "#     # Otsu threshold\n",
    "#     _, otsu = cv2.threshold(\n",
    "#         img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "#     )\n",
    "\n",
    "#     # Adaptive threshold\n",
    "#     adaptive = cv2.adaptiveThreshold(\n",
    "#         img,\n",
    "#         255,\n",
    "#         cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "#         cv2.THRESH_BINARY,\n",
    "#         41,\n",
    "#         7\n",
    "#     )\n",
    "\n",
    "#     # Combine Binary & Otsu\n",
    "#     combined = cv2.bitwise_and(binary, otsu)\n",
    "\n",
    "#     # --------------------------------------\n",
    "#     # Morphology (1-channel only)\n",
    "#     # --------------------------------------\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "\n",
    "    \n",
    "    \n",
    "#     opened = cv2.morphologyEx(combined, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "#     closed = cv2.morphologyEx(opened, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "#     # closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    \n",
    "  \n",
    "\n",
    "#     # Enforce clean binary\n",
    "#     _,closed = cv2.threshold(closed, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "#     closed = closed.astype(np.uint8)\n",
    "\n",
    "#     # --------------------------------------\n",
    "#     # Connected Components (FINAL MASK)\n",
    "#     # --------------------------------------\n",
    "#     num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n",
    "#         closed, connectivity=8\n",
    "#     )\n",
    "\n",
    "#     final_mask = np.zeros_like(closed)\n",
    "#     for i in range(1, num_labels):\n",
    "#         area = stats[i, cv2.CC_STAT_AREA]\n",
    "#         if area >= 100 and area <= 5000:  # Minimum area threshold\n",
    "#             final_mask[labels == i] = 255   \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#     # --------------------------------------\n",
    "#     # Apply mask to original frame\n",
    "#     # --------------------------------------\n",
    "#     masked_output = cv2.bitwise_and(\n",
    "#         resized_frame, resized_frame, mask=final_mask\n",
    "#     )\n",
    "\n",
    "#     # --------------------------------------\n",
    "#     # Visualization\n",
    "#     # --------------------------------------\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "#     cv2.imshow(\"Original\", resized_frame)\n",
    "#     # cv2.imshow(\"Binary\", binary)\n",
    "#     # cv2.imshow(\"Otsu\", otsu)\n",
    "#     # cv2.imshow(\"combined\", combined)\n",
    "#     # cv2.imshow(\"Refined\", closed)\n",
    "#     cv2.imshow(\"Final Mask\", final_mask)\n",
    "#     cv2.imshow(\"Masked Output\", masked_output)\n",
    "\n",
    "\n",
    "#     if cv2.waitKey(int(1000 / fps)) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d067a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 2 # Number of clusters (colors)\n",
    "# # Define criteria: stop after 10 iterations or if the epsilon (accuracy) is 1.0\n",
    "# criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "# # Open the video file (replace 'input_video.mp4' with your video file path)\n",
    "# cap = cv2.VideoCapture('Mallet_videos/IMG_9117.MOV')\n",
    "\n",
    "# if not cap.isOpened():\n",
    "#     print(\"Error opening video file. Check the path and file format.\")\n",
    "#     exit()\n",
    "# else:\n",
    "#     print(\"Video opened successfully.\")\n",
    "\n",
    "# desired_width = 640\n",
    "# desired_height = 1000\n",
    "# display_size = (desired_width, desired_height)\n",
    "\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # 1. Reshape the frame for K-Means: from (height, width, 3) to (pixels, 3)\n",
    "#     pixel_values = frame.reshape((-1, 3))\n",
    "#     # Convert to float32 data type, which is required by the OpenCV kmeans function\n",
    "#     pixel_values = np.float32(pixel_values)\n",
    "\n",
    "#     # 2. Apply K-Means Clustering\n",
    "#     # 'attempts' is the number of times the algorithm is executed with different initial labels\n",
    "#     _, labels, centers = cv2.kmeans(pixel_values, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "#     # 3. Reconstruct the segmented image from the centers and labels\n",
    "#     # Convert centers back to uint8\n",
    "#     centers = np.uint8(centers)\n",
    "#     # Map labels to their respective cluster center colors\n",
    "#     segmented_data = centers[labels.flatten()]\n",
    "#     # Reshape the data back to the original image dimensions\n",
    "#     segmented_frame = segmented_data.reshape((frame.shape))\n",
    "\n",
    "#     # Display the original and segmented frames\n",
    "#     cv2.imshow('Original Video', frame)\n",
    "#     cv2.imshow('K-Means Segmented Video', segmented_frame)\n",
    "\n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(int(1000 / fps)) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release everything when the job is finished\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07cf275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65fe2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture('Mallet_videos/IMG_9117.MOV')\n",
    "\n",
    "# if not cap.isOpened():\n",
    "#     print(\"Error opening video file. Check the path and file format.\")\n",
    "#     exit()\n",
    "# else:\n",
    "#     print(\"Video opened successfully.\")\n",
    "\n",
    "# desired_width = 640\n",
    "# desired_height = 1000\n",
    "# display_size = (desired_width, desired_height)\n",
    "\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # --------------------------------------\n",
    "#     # Resize (BGR, 3-channel)\n",
    "#     # --------------------------------------\n",
    "#     resized_frame = cv2.resize(\n",
    "#         frame, display_size, interpolation=cv2.INTER_AREA\n",
    "#     )\n",
    "#     hsv = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2HSV)\n",
    "#     H, S, V = cv2.split(hsv)\n",
    "\n",
    "#     lower_orange = np.array([5, 80, 80])\n",
    "#     upper_orange = np.array([25, 255, 255])\n",
    "\n",
    "#     color_mask = cv2.inRange(hsv, lower_orange, upper_orange)\n",
    "\n",
    "#     _, sat_mask = cv2.threshold(S, 60, 255, cv2.THRESH_BINARY)\n",
    "#     color_mask = cv2.bitwise_and(color_mask, sat_mask)\n",
    "\n",
    "\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "#     clean = cv2.morphologyEx(color_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "#     clean = cv2.morphologyEx(clean, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "#     num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(clean, 8)\n",
    "\n",
    "#     final_mask = np.zeros_like(clean)\n",
    "#     for i in range(1, num_labels):\n",
    "#         area = stats[i, cv2.CC_STAT_AREA]\n",
    "#         if 500 < area < 20000:\n",
    "#             final_mask[labels == i] = 255\n",
    "\n",
    "#     edges = cv2.Canny(V, 50, 150)\n",
    "#     edges = cv2.dilate(edges, None)\n",
    "\n",
    "#     final_mask = cv2.bitwise_or(final_mask, edges)\n",
    "\n",
    "#     cv2.imshow(\"Final Mask\", final_mask)\n",
    "#     if cv2.waitKey(int(1000 / fps)) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
