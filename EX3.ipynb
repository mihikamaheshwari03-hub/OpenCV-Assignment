{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "439270b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1355e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aruco_dict_from_filename(filename):\n",
    "    match = re.search(r'(\\d+)x(\\d+)_(\\d+)', filename)\n",
    "    if not match:\n",
    "        raise ValueError(\"Invalid filename format\")\n",
    "\n",
    "    bits = int(match.group(1))\n",
    "    total = int(match.group(3))\n",
    "\n",
    "    key = f'DICT_{bits}X{bits}_{total}'\n",
    "    return getattr(aruco, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e815bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad_size(quad):\n",
    "    quad = quad.reshape(4,2)\n",
    "    return min(\n",
    "        np.linalg.norm(quad[0]-quad[1]),\n",
    "        np.linalg.norm(quad[1]-quad[2])\n",
    "    )\n",
    "\n",
    "def enhance_for_large_markers(gray):\n",
    "    clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8,8))\n",
    "    eq = clahe.apply(gray)\n",
    "\n",
    "    blur = cv2.GaussianBlur(eq, (5,5), 0)\n",
    "    sharp = cv2.addWeighted(eq, 1.15, blur, -0.15, 0)\n",
    "\n",
    "    return sharp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd92d8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "filename = \"ArUco_videos/Video7(5x5_250).mp4\"\n",
    "cap = cv2.VideoCapture(filename)\n",
    "get_aruco_dict_from_filename(filename)\n",
    "\n",
    "dict_id = get_aruco_dict_from_filename(filename)\n",
    "dictionary = aruco.getPredefinedDictionary(dict_id)\n",
    "parameters = aruco.DetectorParameters()\n",
    "detector = aruco.ArucoDetector(dictionary, parameters)\n",
    "\n",
    "print(\"Video opened:\", cap.isOpened())\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame2 = frame.copy()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 1. Mild contrast normalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8,8))\n",
    "    gray_eq = clahe.apply(gray)\n",
    "\n",
    "    # 2. Edge-preserving denoising (very mild)\n",
    "    denoised = cv2.bilateralFilter(gray_eq, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "\n",
    "    # 3. Mild unsharp masking (geometry-preserving)\n",
    "    blur = cv2.GaussianBlur(denoised, (5,5), 0)\n",
    "    sharp = cv2.addWeighted(denoised, 1.2, blur, -0.2, 0)\n",
    "    \n",
    "\n",
    "    corners, ids, rejected = detector.detectMarkers(gray)\n",
    "    small_candidates = any(quad_size(q) < 25 for q in rejected)\n",
    "    if ids is None and not small_candidates:\n",
    "        processed = enhance_for_large_markers(gray)\n",
    "        corners, ids, rejected = detector.detectMarkers(processed)\n",
    "        aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "    else:\n",
    "        \n",
    "        corners, ids, rejected = detector.detectMarkers(gray)\n",
    "        aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "\n",
    "    # corners2, ids2, rejected2 = detector.detectMarkers(blur)\n",
    "    # corners3, ids3, rejected3 = detector.detectMarkers(sharp)\n",
    "    # # corners4, ids4, rejected4 = detector.detectMarkers(blur2)\n",
    "    # # corners5, ids5, rejected5 = detector.detectMarkers(unsharp2)\n",
    "    # if ids is not None:\n",
    "    #     aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "    #     aruco.drawDetectedMarkers(blur, corners2, ids2)\n",
    "    #     aruco.drawDetectedMarkers(sharp, corners3, ids3)\n",
    "        # aruco.drawDetectedMarkers(blur2, corners4, ids4)\n",
    "        # aruco.drawDetectedMarkers(frame2, corners5, ids5)\n",
    "    cv2.imshow(\"ArUco Detection\", frame)\n",
    "    # cv2.imshow(\"blur\", blur)\n",
    "    # cv2.imshow(\"unsharp\", sharp)\n",
    "    # cv2.imshow(\"blur2\", blur2)\n",
    "    # cv2.imshow(\"unsharp2\", frame2)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48627d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Core imports\n",
    "# import cv2\n",
    "# import cv2.aruco as aruco\n",
    "# import re\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from IPython.display import clear_output\n",
    "# plt.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "# # Helper functions: parsing, filters, detection, visualization\n",
    "# def get_aruco_dict_from_filename(filename):\n",
    "#     # expect patterns like '4x4_250' inside filename\n",
    "#     match = re.search(r'(\\d+)x(\\d+)_(\\d+)', filename)\n",
    "#     if not match:\n",
    "#         raise ValueError('Invalid filename format: expected e.g. 4x4_250')\n",
    "#     bits = int(match.group(1))\n",
    "#     total = int(match.group(3))\n",
    "#     key = f'DICT_{bits}X{bits}_{total}'\n",
    "#     if not hasattr(aruco, key):\n",
    "#         raise ValueError('ArUco dictionary not found: ' + key)\n",
    "#     return getattr(aruco, key)\n",
    "\n",
    "# def unsharp_mask(gray, kernel_size=(5,5), sigma=1.0, amount=1.5):\n",
    "#     # classic unsharp: sharpen = (1+amount)*orig - amount*blur\n",
    "#     blur = cv2.GaussianBlur(gray, kernel_size, sigma)\n",
    "#     sharpen = cv2.addWeighted(gray, 1+amount, blur, -amount, 0)\n",
    "#     return np.clip(sharpen, 0, 255).astype(np.uint8)\n",
    "\n",
    "# def laplacian_sharpen(gray, k=1.0):\n",
    "#     lap = cv2.Laplacian(gray, cv2.CV_16S, ksize=3)\n",
    "#     lap = cv2.convertScaleAbs(lap)\n",
    "#     sharpen = cv2.addWeighted(gray, 1.0, lap, 0.7, 0)\n",
    "#     return np.clip(sharpen,0,255).astype(np.uint8)\n",
    "\n",
    "# def apply_filters(gray):\n",
    "#     # produce a set of candidate images for detection comparison\n",
    "#     results = {}\n",
    "#     results['orig'] = gray\n",
    "#     results['mean'] = cv2.blur(gray, (5,5))\n",
    "#     results['gauss'] = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "#     results['median'] = cv2.medianBlur(gray, 5)\n",
    "#     results['bilateral'] = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "#     results['clahe'] = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(gray)\n",
    "#     results['unsharp'] = unsharp_mask(results['clahe'], kernel_size=(5,5), sigma=1.0, amount=1.2)\n",
    "#     results['lap_sharp'] = laplacian_sharpen(results['clahe'])\n",
    "#     results['canny'] = cv2.Canny(results['gauss'], 50, 150)\n",
    "#     return results\n",
    "\n",
    "# def detect_and_visualize(frame, dictionary, parameters=None, draw_on=None):\n",
    "#     # Returns annotated output and detection meta for a BGR frame\n",
    "#     if parameters is None:\n",
    "#         parameters = aruco.DetectorParameters()\n",
    "#     detector = aruco.ArucoDetector(dictionary, parameters)\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     candidates = apply_filters(gray)\n",
    "#     detections = {}\n",
    "#     for name, img in candidates.items():\n",
    "#         # detector.detectMarkers expects grayscale images\n",
    "#         try:\n",
    "#             corners, ids, rejected = detector.detectMarkers(img)\n",
    "#         except Exception:\n",
    "#             # fallback: try converting to uint8 if needed\n",
    "#             corners, ids, rejected = detector.detectMarkers(img.astype(np.uint8))\n",
    "#         detections[name] = (corners, ids)\n",
    "#     # Build a color annotation of the original frame showing best guess(s)\n",
    "#     annotated = frame.copy() if draw_on is None else draw_on\n",
    "#     # Draw detections for selected stages to compare: orig, clahe, unsharp, lap_sharp\n",
    "#     for stage in ['orig','clahe','unsharp','lap_sharp']:\n",
    "#         corners_ids = detections.get(stage)\n",
    "#         if corners_ids is None:\n",
    "#             continue\n",
    "#         corners, ids = corners_ids\n",
    "#         if ids is not None:\n",
    "#             # use different colors per stage (visual comparison)\n",
    "#             color = (0,255,0) if stage=='orig' else ((255,0,0) if stage=='clahe' else (0,0,255))\n",
    "#             aruco.drawDetectedMarkers(annotated, corners, ids, borderColor=color)\n",
    "#     return annotated, candidates, detections\n",
    "\n",
    "# def show_comparison_grid(orig_bgr, candidates, annotated=None):\n",
    "#     # show: orig color, mean, gauss, clahe, unsharp, lap_sharp, canny, annotated\n",
    "#     ncols = 4\n",
    "#     imgs = []\n",
    "#     imgs.append((cv2.cvtColor(orig_bgr, cv2.COLOR_BGR2RGB),'original'))\n",
    "#     order = ['mean','gauss','clahe','unsharp','lap_sharp','canny']\n",
    "#     for k in order:\n",
    "#         img = candidates.get(k)\n",
    "#         if img is None:\n",
    "#             imgs.append((np.zeros_like(cv2.cvtColor(orig_bgr, cv2.COLOR_BGR2GRAY)),'') )\n",
    "#         else:\n",
    "#             if img.ndim==2:\n",
    "#                 imgs.append((cv2.cvtColor(img, cv2.COLOR_GRAY2RGB), k))\n",
    "#             else:\n",
    "#                 imgs.append((img, k))\n",
    "#     if annotated is not None:\n",
    "#         imgs.append((cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB),'annotated'))\n",
    "#     total = len(imgs)\n",
    "#     rows = (total + ncols - 1)//ncols\n",
    "#     fig, axes = plt.subplots(rows, ncols, figsize=(4*ncols,3*rows))\n",
    "#     axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]\n",
    "#     for ax in axes:\n",
    "#         ax.axis('off')\n",
    "#     for i, (img, title) in enumerate(imgs):\n",
    "#         axes[i].imshow(img, cmap='gray')\n",
    "#         axes[i].set_title(title)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Main demo: process a video and display comparisons for successive frames\n",
    "# filename = 'ArUco_videos/Video9(4x4_250).mp4'\n",
    "# cap = cv2.VideoCapture(filename)\n",
    "# if not cap.isOpened():\n",
    "#     raise RuntimeError('Failed to open video: ' + filename)\n",
    "\n",
    "# dict_id = get_aruco_dict_from_filename(filename)\n",
    "# dictionary = aruco.getPredefinedDictionary(dict_id)\n",
    "# parameters = aruco.DetectorParameters()\n",
    "# # Tune detector parameters here if needed, e.g.:\n",
    "# parameters.adaptiveThreshConstant = 7\n",
    "# parameters.cornerRefinementMethod = aruco.CORNER_REFINE_SUBPIX if hasattr(aruco, 'CORNER_REFINE_SUBPIX') else 1\n",
    "\n",
    "# frame_idx = 0\n",
    "# max_frames = 200\n",
    "# # we'll show one frame every `step` frames to keep notebook responsive\n",
    "# step = 10\n",
    "# while frame_idx < max_frames:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "#     if frame_idx % step != 0:\n",
    "#         frame_idx += 1\n",
    "#         continue\n",
    "#     annotated, candidates, detections = detect_and_visualize(frame, dictionary, parameters)\n",
    "#     clear_output(wait=True)\n",
    "#     print(f'Frame {frame_idx}')\n",
    "#     show_comparison_grid(frame, candidates, annotated=annotated)\n",
    "#     frame_idx += 1\n",
    "# cap.release()\n",
    "# print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30872fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe311670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83b658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
